{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import hydra\n",
    "import numpy as np\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from lightning import Trainer\n",
    "from lightning_modules import PortraitNetModule, PortraitDataModule\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config, instantiate model, datamodule and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"\"\n",
    "\n",
    "with initialize(version_base=\"1.3\", config_path=\"./configs\"):\n",
    "    cfg = compose(config_name=\"eval.yaml\", overrides=[\"experiment=v2-eg-full\"])\n",
    "    print(cfg)\n",
    "\n",
    "def concat_images(images):\n",
    "    if len(images.shape) != 4:\n",
    "        raise ValueError(\"image shape should be (N, C, H, W)\")\n",
    "    image_list = np.split(images, images.shape[0], axis=0)\n",
    "    image_list = [np.squeeze(image, axis=0) for image in image_list]\n",
    "    concatenated_image = np.concatenate(image_list, axis=-1).transpose((1, 2, 0))\n",
    "    return concatenated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PortraitNetModule(cfg.model)\n",
    "datamodule = PortraitDataModule(cfg.data)\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=[7], logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=model, datamodule=datamodule, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rawdata_with_titles(image_list, column_titles):\n",
    "    num_images = len(image_list) \n",
    "    num_columns = len(image_list[0])\n",
    "\n",
    "    fig, axes = plt.subplots(num_images, num_columns, figsize=(12, 3*num_images + 0.1))\n",
    "\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, ax in enumerate(row):\n",
    "            image = image_list[i][j]            \n",
    "            ax.imshow(image)\n",
    "            ax.axis('off')\n",
    "            if i == num_images-1:\n",
    "                title = column_titles[j]\n",
    "                ax.set_title(title, y=-0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"dataset.pdf\")\n",
    "\n",
    "datamodule.setup()\n",
    "train_dataloader = datamodule.test_dataloader()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "input_ori, input_aug, boundary, mask = batch\n",
    "\n",
    "img_list = []\n",
    "for i in range(4):\n",
    "    img_ori = concat_images(model.tensor2image(input_ori[i:i+1]))\n",
    "    img_aug = concat_images(model.tensor2image(input_aug[i:i+1]))\n",
    "    img_mask = concat_images(model.label2image(mask[i:i+1]))\n",
    "    img_boundary = concat_images(model.label2image(boundary[i:i+1]))\n",
    "    img_list.append([img_ori, img_aug, img_mask, img_boundary])\n",
    "\n",
    "column_titles = [\"Deformation augmentations\", \"Texture augmentations\", \"Mask\", \"Boundary\"]\n",
    "\n",
    "plot_rawdata_with_titles(img_list, column_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_map(feature_map_tensor):\n",
    "    feature_map_array = feature_map_tensor.detach().cpu().numpy()\n",
    "\n",
    "    batch_size, num_channels, height, width = feature_map_array.shape\n",
    "    assert batch_size == 1\n",
    "    feature_map_array = feature_map_array[0]\n",
    "\n",
    "    grayscale_image = np.zeros((height, width))\n",
    "\n",
    "    for i in range(num_channels):\n",
    "        grayscale_image += feature_map_array[i, :, :]\n",
    "\n",
    "    grayscale_image /= num_channels\n",
    "    grayscale_image = grayscale_image - np.min(grayscale_image)\n",
    "    grayscale_image = grayscale_image / np.max(grayscale_image)\n",
    "\n",
    "    return grayscale_image\n",
    "\n",
    "\n",
    "def plot_featuremap_with_titles(image_list, column_titles):\n",
    "    num_images = len(image_list)\n",
    "    num_columns = len(image_list[0])\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        num_images, num_columns, figsize=(3*num_columns, 3*num_images)\n",
    "    )\n",
    "\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, ax in enumerate(row):\n",
    "            print(i, j)\n",
    "            image = image_list[i][j]\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")\n",
    "            title = column_titles[i][j]\n",
    "            ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"feature-map-after-training.pdf\")\n",
    "\n",
    "datamodule.setup()\n",
    "train_dataloader = datamodule.test_dataloader()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "input_ori, input_aug, boundary, mask = batch\n",
    "\n",
    "feature2x, feature4x, feature8x, feature16x, feature32x = model.model.encoder(\n",
    "    input_ori[:1]\n",
    ")\n",
    "up16x = model.model.upsample32x(model.model.d_block32x(feature32x))\n",
    "up8x = model.model.upsample16x(model.model.d_block16x(feature16x + up16x))\n",
    "up4x = model.model.upsample8x(model.model.d_block8x(feature8x + up8x))\n",
    "up2x = model.model.upsample4x(model.model.d_block4x(feature4x + up4x))\n",
    "up1x = model.model.upsample2x(model.model.d_block2x(feature2x + up2x))\n",
    "\n",
    "mask_logits = model.model.mask_conv(up1x)\n",
    "img_input = concat_images(model.tensor2image(input_ori[:1]))\n",
    "img_mask = concat_images(model.logits2image(mask_logits))\n",
    "\n",
    "encoder_imgs = [\n",
    "    img_input,\n",
    "    visualize_feature_map(feature2x),\n",
    "    visualize_feature_map(feature4x),\n",
    "    visualize_feature_map(feature8x),\n",
    "    visualize_feature_map(feature16x),\n",
    "    visualize_feature_map(feature32x),\n",
    "]\n",
    "encoder_titles = [\n",
    "    \"Input image\",\n",
    "    \"Encoder-feature 2x\",\n",
    "    \"Encoder-feature 4x\",\n",
    "    \"Encoder-feature 8x\",\n",
    "    \"Encoder-feature 16x\",\n",
    "    \"Encoder-feature 32x\",\n",
    "]\n",
    "\n",
    "decoder_imgs = [\n",
    "    img_mask,\n",
    "    visualize_feature_map(up1x),\n",
    "    visualize_feature_map(up2x),\n",
    "    visualize_feature_map(up4x),\n",
    "    visualize_feature_map(up8x),\n",
    "    visualize_feature_map(up16x),\n",
    "]\n",
    "decoder_titles = [\n",
    "    \"Mask prediction\",\n",
    "    \"Decoder-feature 1x\",\n",
    "    \"Decoder-feature 2x\",\n",
    "    \"Decoder-feature 4x\",\n",
    "    \"Decoder-feature 8x\",\n",
    "    \"Decoder-feature 16x\"\n",
    "]\n",
    "\n",
    "plot_featuremap_with_titles([encoder_imgs, decoder_imgs], [encoder_titles, decoder_titles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cva2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
